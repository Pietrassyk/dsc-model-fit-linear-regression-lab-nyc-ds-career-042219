{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit in Linear Regression - Lab\n",
    "\n",
    "## Introduction\n",
    "In this lab, you'll learn how to evaluate your model results, and you'll learn methods to select the appropriate features using stepwise selection.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Analyze the results of regression and R-squared and adjusted-R-squared \n",
    "* Understand and apply forward and backward predictor selection\n",
    "\n",
    "## The Boston Housing Data once more\n",
    "\n",
    "We pre-processed the Boston Housing Data the same way we did before:\n",
    "\n",
    "- We dropped \"ZN\" and \"NOX\" completely\n",
    "- We categorized \"RAD\" in 3 bins and \"TAX\" in 4 bins\n",
    "- We used min-max-scaling on \"B\", \"CRIM\" and \"DIS\" (and logtransformed all of them first, except \"B\")\n",
    "- We used standardization on \"AGE\", \"INDUS\", \"LSTAT\" and \"PTRATIO\" (and logtransformed all of them first, except for \"AGE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "boston_features = boston_features.drop([\"NOX\",\"ZN\"],axis=1)\n",
    "\n",
    "# first, create bins for based on the values observed. 3 values will result in 2 bins\n",
    "bins = [0,6,  24]\n",
    "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
    "bins_rad = bins_rad.cat.as_unordered()\n",
    "\n",
    "# first, create bins for based on the values observed. 4 values will result in 3 bins\n",
    "bins = [0, 270, 360, 712]\n",
    "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
    "bins_tax = bins_tax.cat.as_unordered()\n",
    "\n",
    "tax_dummy = pd.get_dummies(bins_tax, prefix=\"TAX\")\n",
    "rad_dummy = pd.get_dummies(bins_rad, prefix=\"RAD\")\n",
    "boston_features = boston_features.drop([\"RAD\",\"TAX\"], axis=1)\n",
    "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
    "\n",
    "age = boston_features[\"AGE\"]\n",
    "b = boston_features[\"B\"]\n",
    "logcrim = np.log(boston_features[\"CRIM\"])\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "logindus = np.log(boston_features[\"INDUS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "logptratio = np.log(boston_features[\"PTRATIO\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"CRIM\"] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"AGE\"] = (age-np.mean(age))/np.sqrt(np.var(age))\n",
    "boston_features[\"INDUS\"] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "boston_features[\"PTRATIO\"] = (logptratio-np.mean(logptratio))/(np.sqrt(np.var(logptratio)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for stepwise selection is copied below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT                          with p-value 9.27989e-122\n",
      "Add  RM                             with p-value 1.98621e-16\n",
      "Add  PTRATIO                        with p-value 2.5977e-12\n",
      "Add  DIS                            with p-value 2.85496e-09\n",
      "Add  B                              with p-value 2.77572e-06\n",
      "Add  TAX_(0, 270]                   with p-value 0.000855799\n",
      "Add  CHAS                           with p-value 0.00151282\n",
      "Add  INDUS                          with p-value 0.00588575\n"
     ]
    }
   ],
   "source": [
    "predictors = boston_features\n",
    "y  = pd.DataFrame(boston.target, columns= [\"price\"])\n",
    "initial_list1 = list(X.columns)\n",
    "feature_list = stepwise_selection(predictors, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final model again in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "final_model = sm.OLS(y,sm.add_constant(boston_features[feature_list])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.776</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   215.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 May 2019</td> <th>  Prob (F-statistic):</th> <td>2.69e-156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:02:36</td>     <th>  Log-Likelihood:    </th> <td> -1461.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   2941.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   497</td>      <th>  BIC:               </th> <td>   2979.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    4.8980</td> <td>    2.813</td> <td>    1.742</td> <td> 0.082</td> <td>   -0.628</td> <td>   10.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>        <td>   -5.5932</td> <td>    0.319</td> <td>  -17.538</td> <td> 0.000</td> <td>   -6.220</td> <td>   -4.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>           <td>    2.8294</td> <td>    0.386</td> <td>    7.333</td> <td> 0.000</td> <td>    2.071</td> <td>    3.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>      <td>   -1.3265</td> <td>    0.226</td> <td>   -5.878</td> <td> 0.000</td> <td>   -1.770</td> <td>   -0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>          <td>   -9.1984</td> <td>    1.333</td> <td>   -6.898</td> <td> 0.000</td> <td>  -11.818</td> <td>   -6.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>            <td>    3.9052</td> <td>    0.931</td> <td>    4.195</td> <td> 0.000</td> <td>    2.076</td> <td>    5.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX_(0, 270]</th> <td>    1.4418</td> <td>    0.552</td> <td>    2.614</td> <td> 0.009</td> <td>    0.358</td> <td>    2.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>         <td>    2.7988</td> <td>    0.791</td> <td>    3.539</td> <td> 0.000</td> <td>    1.245</td> <td>    4.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>        <td>   -0.9574</td> <td>    0.346</td> <td>   -2.766</td> <td> 0.006</td> <td>   -1.637</td> <td>   -0.277</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>114.307</td> <th>  Durbin-Watson:     </th> <td>   1.088</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 482.579</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.945</td>  <th>  Prob(JB):          </th> <td>1.62e-105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.395</td>  <th>  Cond. No.          </th> <td>    96.8</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.776\n",
       "Model:                            OLS   Adj. R-squared:                  0.773\n",
       "Method:                 Least Squares   F-statistic:                     215.7\n",
       "Date:                Sun, 05 May 2019   Prob (F-statistic):          2.69e-156\n",
       "Time:                        20:02:36   Log-Likelihood:                -1461.3\n",
       "No. Observations:                 506   AIC:                             2941.\n",
       "Df Residuals:                     497   BIC:                             2979.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            4.8980      2.813      1.742      0.082      -0.628      10.424\n",
       "LSTAT           -5.5932      0.319    -17.538      0.000      -6.220      -4.967\n",
       "RM               2.8294      0.386      7.333      0.000       2.071       3.587\n",
       "PTRATIO         -1.3265      0.226     -5.878      0.000      -1.770      -0.883\n",
       "DIS             -9.1984      1.333     -6.898      0.000     -11.818      -6.579\n",
       "B                3.9052      0.931      4.195      0.000       2.076       5.734\n",
       "TAX_(0, 270]     1.4418      0.552      2.614      0.009       0.358       2.526\n",
       "CHAS             2.7988      0.791      3.539      0.000       1.245       4.353\n",
       "INDUS           -0.9574      0.346     -2.766      0.006      -1.637      -0.277\n",
       "==============================================================================\n",
       "Omnibus:                      114.307   Durbin-Watson:                   1.088\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              482.579\n",
       "Skew:                           0.945   Prob(JB):                    1.62e-105\n",
       "Kurtosis:                       7.395   Cond. No.                         96.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where our stepwise procedure mentions that \"CHAS\" was added with a p-value of 0.00151282, but our statsmodels output returns a p-value of 0.000. What is the intuition behind this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use feature ranking to select the 5 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select = 5)\n",
    "selector = selector.fit(predictors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 8, 5, 1, 7, 1, 3, 1, 1, 2, 9, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.93498961  3.43718997 -6.58036332  4.65357304 -6.25217488]\n",
      "-0.4973982153788903\n"
     ]
    }
   ],
   "source": [
    "estimators = selector.estimator_\n",
    "print(estimators.coef_)\n",
    "print(estimators.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear regression model again using the 5 columns selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model = LinearRegression()\n",
    "predictors_sk = boston_features.loc[:,selector.support_ ]\n",
    "sk_model.fit(predictors_sk,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predict $\\hat y$ using your model. you can use `.predict()` in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictions = sk_model.predict(predictors_sk)\n",
    "#sk_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f078c3336d8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(sk_predictions)\n",
    "sns.distplot(boston_features[\"CRIM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the formulas of R-squared and adjusted-R-squared below, and your Python/numpy knowledge, compute them and contrast them with the R-squared and adjusted-R-squared in your statsmodels output using stepwise selection. Which of the two models would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SS_{residual} = \\sum (y - \\hat{y})^2 $\n",
    "\n",
    "$SS_{total} = \\sum (y - \\bar{y})^2 $\n",
    "\n",
    "$R^2 = 1- \\dfrac{SS_{residual}}{SS_{total}}$\n",
    "\n",
    "$R^2_{adj}= 1-(1-R^2)\\dfrac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform variable selection using forward selection, using this resource: https://planspace.org/20150423-forward_selection_with_statsmodels/. Note that this time features are added based on the adjusted-R-squared!\n",
    "- Tweak the code in the `stepwise_selection()`-function written above to just perform forward selection based on the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Great! You now performed your own feature selection methods!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
