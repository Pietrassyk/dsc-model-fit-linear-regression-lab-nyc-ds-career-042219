{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit in Linear Regression - Lab\n",
    "\n",
    "## Introduction\n",
    "In this lab, you'll learn how to evaluate your model results, and you'll learn methods to select the appropriate features using stepwise selection.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Analyze the results of regression and R-squared and adjusted-R-squared \n",
    "* Understand and apply forward and backward predictor selection\n",
    "\n",
    "## The Boston Housing Data once more\n",
    "\n",
    "We pre-processed the Boston Housing Data the same way we did before:\n",
    "\n",
    "- We dropped \"ZN\" and \"NOX\" completely\n",
    "- We categorized \"RAD\" in 3 bins and \"TAX\" in 4 bins\n",
    "- We used min-max-scaling on \"B\", \"CRIM\" and \"DIS\" (and logtransformed all of them first, except \"B\")\n",
    "- We used standardization on \"AGE\", \"INDUS\", \"LSTAT\" and \"PTRATIO\" (and logtransformed all of them first, except for \"AGE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "boston_features = boston_features.drop([\"NOX\",\"ZN\"],axis=1)\n",
    "\n",
    "# first, create bins for based on the values observed. 3 values will result in 2 bins\n",
    "bins = [0,6,  24]\n",
    "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
    "bins_rad = bins_rad.cat.as_unordered()\n",
    "\n",
    "# first, create bins for based on the values observed. 4 values will result in 3 bins\n",
    "bins = [0, 270, 360, 712]\n",
    "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
    "bins_tax = bins_tax.cat.as_unordered()\n",
    "\n",
    "tax_dummy = pd.get_dummies(bins_tax, prefix=\"TAX\")\n",
    "rad_dummy = pd.get_dummies(bins_rad, prefix=\"RAD\")\n",
    "boston_features = boston_features.drop([\"RAD\",\"TAX\"], axis=1)\n",
    "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
    "\n",
    "age = boston_features[\"AGE\"]\n",
    "b = boston_features[\"B\"]\n",
    "logcrim = np.log(boston_features[\"CRIM\"])\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "logindus = np.log(boston_features[\"INDUS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "logptratio = np.log(boston_features[\"PTRATIO\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"CRIM\"] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"AGE\"] = (age-np.mean(age))/np.sqrt(np.var(age))\n",
    "boston_features[\"INDUS\"] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "boston_features[\"PTRATIO\"] = (logptratio-np.mean(logptratio))/(np.sqrt(np.var(logptratio)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for stepwise selection is copied below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  DIS                            with p-value 2.82884e-90\n",
      "Add  RAD_(6, 24]                    with p-value 6.953e-72\n",
      "Add  RAD_(0, 6]                     with p-value 1.4733e-51\n",
      "Add  INDUS                          with p-value 2.24098e-21\n",
      "Add  B                              with p-value 3.07968e-09\n",
      "Add  LSTAT                          with p-value 1.90996e-06\n",
      "Add  TAX_(0, 270]                   with p-value 0.00039981\n"
     ]
    }
   ],
   "source": [
    "predictors = boston_features.drop(\"CRIM\", axis = 1)\n",
    "y = boston_features[\"CRIM\"]\n",
    "initial_list1 = list(X.columns)\n",
    "feature_list = stepwise_selection(predictors, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final model again in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "final_model = sm.OLS(boston_features[\"CRIM\"],sm.add_constant(boston_features[feature_list])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>CRIM</td>       <th>  R-squared:         </th> <td>   0.829</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.827</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   403.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 May 2019</td> <th>  Prob (F-statistic):</th> <td>8.86e-188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:36:04</td>     <th>  Log-Likelihood:    </th> <td>  481.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>  -948.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   499</td>      <th>  BIC:               </th> <td>  -918.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    0.4907</td> <td>    0.014</td> <td>   33.908</td> <td> 0.000</td> <td>    0.462</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>          <td>   -0.3372</td> <td>    0.028</td> <td>  -12.006</td> <td> 0.000</td> <td>   -0.392</td> <td>   -0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD_(6, 24]</th>  <td>    0.3421</td> <td>    0.008</td> <td>   43.309</td> <td> 0.000</td> <td>    0.327</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD_(0, 6]</th>   <td>    0.1486</td> <td>    0.010</td> <td>   15.236</td> <td> 0.000</td> <td>    0.129</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>        <td>    0.0430</td> <td>    0.007</td> <td>    6.051</td> <td> 0.000</td> <td>    0.029</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>            <td>   -0.1081</td> <td>    0.020</td> <td>   -5.322</td> <td> 0.000</td> <td>   -0.148</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>        <td>    0.0243</td> <td>    0.005</td> <td>    4.426</td> <td> 0.000</td> <td>    0.014</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX_(0, 270]</th> <td>   -0.0428</td> <td>    0.012</td> <td>   -3.564</td> <td> 0.000</td> <td>   -0.066</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.253</td> <th>  Durbin-Watson:     </th> <td>   0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.119</td> <th>  Jarque-Bera (JB):  </th> <td>   4.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.223</td> <th>  Prob(JB):          </th> <td>   0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.921</td> <th>  Cond. No.          </th> <td>2.95e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.57e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   CRIM   R-squared:                       0.829\n",
       "Model:                            OLS   Adj. R-squared:                  0.827\n",
       "Method:                 Least Squares   F-statistic:                     403.3\n",
       "Date:                Sun, 05 May 2019   Prob (F-statistic):          8.86e-188\n",
       "Time:                        19:36:04   Log-Likelihood:                 481.17\n",
       "No. Observations:                 506   AIC:                            -948.3\n",
       "Df Residuals:                     499   BIC:                            -918.8\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            0.4907      0.014     33.908      0.000       0.462       0.519\n",
       "DIS             -0.3372      0.028    -12.006      0.000      -0.392      -0.282\n",
       "RAD_(6, 24]      0.3421      0.008     43.309      0.000       0.327       0.358\n",
       "RAD_(0, 6]       0.1486      0.010     15.236      0.000       0.129       0.168\n",
       "INDUS            0.0430      0.007      6.051      0.000       0.029       0.057\n",
       "B               -0.1081      0.020     -5.322      0.000      -0.148      -0.068\n",
       "LSTAT            0.0243      0.005      4.426      0.000       0.014       0.035\n",
       "TAX_(0, 270]    -0.0428      0.012     -3.564      0.000      -0.066      -0.019\n",
       "==============================================================================\n",
       "Omnibus:                        4.253   Durbin-Watson:                   0.548\n",
       "Prob(Omnibus):                  0.119   Jarque-Bera (JB):                4.311\n",
       "Skew:                          -0.223   Prob(JB):                        0.116\n",
       "Kurtosis:                       2.921   Cond. No.                     2.95e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.57e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where our stepwise procedure mentions that \"CHAS\" was added with a p-value of 0.00151282, but our statsmodels output returns a p-value of 0.000. What is the intuition behind this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use feature ranking to select the 5 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select = 5)\n",
    "selector = selector.fit(predictors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 8, 5, 1, 7, 1, 3, 1, 1, 2, 9, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0628093  -0.33300364 -0.12509284 -0.10060689  0.10060689]\n",
      "0.7422307451735434\n"
     ]
    }
   ],
   "source": [
    "estimators = selector.estimator_\n",
    "print(estimators.coef_)\n",
    "print(estimators.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear regression model again using the 5 columns selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model = LinearRegression()\n",
    "predictors_sk = boston_features.loc[:,selector.support_ ]\n",
    "sk_model.fit(predictors_sk,boston_features.CRIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predict $\\hat y$ using your model. you can use `.predict()` in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.31931116e-16,  1.53211022e-01,  1.53134329e-01,  1.71005402e-01,\n",
       "        2.50315148e-01,  1.62520918e-01,  2.76046466e-01,  3.27656361e-01,\n",
       "        3.67370911e-01,  3.44658178e-01,  3.73925958e-01,  3.05940104e-01,\n",
       "        2.82361605e-01,  4.81723670e-01,  4.83077966e-01,  4.81328959e-01,\n",
       "        5.35630777e-01,  5.04683887e-01,  5.07126143e-01,  4.96582305e-01,\n",
       "        5.53641790e-01,  5.13369593e-01,  5.52013484e-01,  5.28913779e-01,\n",
       "        5.00052145e-01,  5.11947027e-01,  4.88505795e-01,  5.25396285e-01,\n",
       "        5.03176625e-01,  5.30388220e-01,  5.43001502e-01,  5.61914080e-01,\n",
       "        5.64453950e-01,  5.44919583e-01,  5.80170154e-01,  2.42642204e-01,\n",
       "        2.86369516e-01,  2.65907476e-01,  3.47698034e-01,  1.54430526e-01,\n",
       "        1.74878389e-01,  3.14468080e-01,  3.25423861e-01,  3.37867436e-01,\n",
       "        3.10491614e-01,  3.45504350e-01,  3.55369755e-01,  3.75945235e-01,\n",
       "        3.86615006e-01,  3.71515063e-01,  2.76566880e-01,  2.01629721e-01,\n",
       "        2.23800170e-01,  2.16123224e-01,  8.02259311e-02,  7.63845430e-02,\n",
       "        1.23439253e-01,  8.56263898e-02,  3.34591259e-01,  2.92462950e-01,\n",
       "        3.31055106e-01,  3.45681303e-01,  2.99318622e-01,  3.13693055e-01,\n",
       "        1.18002529e-01,  1.81665809e-01,  2.02638631e-01,  2.31860506e-01,\n",
       "        3.20918930e-01,  3.15057860e-01,  2.76010889e-01,  3.37472545e-01,\n",
       "        2.79945066e-01,  3.59205703e-01,  2.64354599e-01,  2.83846848e-01,\n",
       "        2.90673931e-01,  2.74589822e-01,  2.29242083e-01,  2.70669928e-01,\n",
       "        1.96078221e-01,  2.04604284e-01,  1.83833890e-01,  1.80697441e-01,\n",
       "        2.17749847e-01,  2.30879411e-01,  2.20385772e-01,  2.53979819e-01,\n",
       "        2.29501343e-01,  2.22661204e-01,  2.09687333e-01,  1.91366895e-01,\n",
       "        1.98344233e-01,  1.58590278e-01,  2.00586615e-01,  3.09935525e-01,\n",
       "        3.03751850e-01,  3.08892409e-01,  2.68143302e-01,  2.49630677e-01,\n",
       "        3.30591366e-01,  3.03094595e-01,  3.75712108e-01,  3.67554114e-01,\n",
       "        3.24008664e-01,  3.18638991e-01,  3.45369910e-01,  3.17488108e-01,\n",
       "        3.14943441e-01,  3.90564198e-01,  2.97073215e-01,  2.89960057e-01,\n",
       "        3.11002318e-01,  3.72628524e-01,  3.26021413e-01,  3.45455483e-01,\n",
       "        3.17814815e-01,  3.32212482e-01,  3.17016171e-01,  3.27808337e-01,\n",
       "        2.50224144e-01,  2.54184569e-01,  2.81476001e-01,  3.31795628e-01,\n",
       "        2.87491560e-01,  3.44028320e-01,  4.30845371e-01,  3.88769932e-01,\n",
       "        4.12611084e-01,  5.16898326e-01,  4.17214604e-01,  5.48600790e-01,\n",
       "        4.74905333e-01,  4.14013837e-01,  5.27607189e-01,  4.69017532e-01,\n",
       "        4.11709716e-01,  4.20925310e-01,  3.84923105e-01,  4.66498800e-01,\n",
       "        4.00868720e-01,  5.81192002e-01,  6.55784284e-01,  6.77775775e-01,\n",
       "        6.37158231e-01,  6.20876022e-01,  6.10511175e-01,  6.20403300e-01,\n",
       "        6.18726818e-01,  6.35420174e-01,  5.82973962e-01,  5.72321299e-01,\n",
       "        5.42609172e-01,  6.10225640e-01,  5.66386429e-01,  6.62320348e-01,\n",
       "        6.23797680e-01,  5.51255633e-01,  5.60992007e-01,  5.67210239e-01,\n",
       "        5.55438519e-01,  5.69989572e-01,  5.93610723e-01,  5.73897512e-01,\n",
       "        6.14668762e-01,  6.42454818e-01,  6.03226656e-01,  5.91681182e-01,\n",
       "        6.17343915e-01,  6.23919552e-01,  5.49863823e-01,  6.17956472e-01,\n",
       "        3.23663142e-01,  2.80104875e-01,  2.71416176e-01,  2.46596097e-01,\n",
       "        2.52074108e-01,  2.25062043e-01,  2.46249925e-01,  2.31697627e-01,\n",
       "        2.45395343e-01,  2.50057096e-01,  2.79245899e-01,  2.89168085e-01,\n",
       "        2.69679185e-01,  2.36425085e-01,  2.28423058e-01,  2.64075808e-01,\n",
       "        3.13103836e-01,  2.70457521e-01,  2.78842618e-01,  2.50406074e-01,\n",
       "        2.74071545e-01,  1.29956448e-01,  8.61368748e-02,  8.18300481e-02,\n",
       "        1.93449343e-01,  2.09284265e-01,  1.86906883e-01,  1.68153291e-01,\n",
       "        1.08282158e-01,  1.77524905e-01,  1.29476678e-01,  1.79481704e-01,\n",
       "        1.21069298e-01,  3.21596410e-01,  3.76136834e-01,  3.85836886e-01,\n",
       "        3.21173499e-01,  4.43161453e-01,  3.47344599e-01,  4.27670797e-01,\n",
       "        3.70278830e-01,  3.24696307e-01,  4.00381767e-01,  3.60605401e-01,\n",
       "        2.06878635e-01,  2.51939847e-01,  2.99716595e-01,  3.03030475e-01,\n",
       "        4.22622905e-01,  4.36208152e-01,  4.80687930e-01,  4.79189810e-01,\n",
       "        4.09310588e-01,  4.63061241e-01,  4.29427755e-01,  4.37400430e-01,\n",
       "        4.03459826e-01,  4.44609794e-01,  4.65042980e-01,  4.49512081e-01,\n",
       "        4.72253329e-01,  4.14536245e-01,  4.46052394e-01,  4.14213610e-01,\n",
       "        4.61792017e-01,  4.60017486e-01,  2.68869625e-01,  2.80945545e-01,\n",
       "        3.02147124e-01,  2.95302735e-01,  2.92077067e-01,  3.14574814e-01,\n",
       "        3.64781983e-01,  3.57007527e-01,  4.17143776e-01,  3.59836020e-01,\n",
       "        3.41120634e-01,  3.56678722e-01,  3.24532281e-01,  3.68773862e-01,\n",
       "        2.68577153e-01,  4.25747738e-01,  2.12661872e-01,  1.80608962e-01,\n",
       "        9.31020782e-02,  4.78650263e-01,  4.87188799e-01,  4.86100825e-01,\n",
       "        4.65647512e-01,  4.64480027e-01,  4.61703498e-01,  5.10026458e-01,\n",
       "        4.67560404e-01,  5.01625354e-01,  5.04883936e-01,  4.72806872e-01,\n",
       "        4.65723075e-01,  2.78807979e-01,  4.03799812e-01,  3.39658538e-01,\n",
       "        3.03350685e-01,  3.72515350e-01,  2.29204993e-01,  2.84854502e-01,\n",
       "        2.93882472e-01,  2.37800964e-01,  2.65436154e-01,  3.66943845e-01,\n",
       "        1.81490407e-01,  1.85141768e-01,  2.37835131e-01,  9.05528439e-02,\n",
       "        3.77025380e-02,  5.76329285e-02,  1.18751051e-01,  1.89730100e-01,\n",
       "        2.07565101e-01,  2.00659728e-01,  1.79242832e-01,  2.64221934e-01,\n",
       "        1.82567400e-01,  2.69135953e-01,  2.68296631e-01,  3.16001127e-01,\n",
       "        2.24034279e-01,  3.25075563e-01,  2.43438544e-01,  2.27654066e-01,\n",
       "        2.03543152e-01,  1.80283897e-01,  2.81103835e-01,  2.89084370e-01,\n",
       "        2.26784516e-01,  2.26098924e-01,  2.59010043e-01,  2.15088292e-01,\n",
       "        4.56089268e-01,  4.20051096e-01,  6.31579315e-01,  5.05509617e-01,\n",
       "        3.89790989e-01,  3.92822940e-01,  4.25821487e-01,  3.86487097e-01,\n",
       "        4.10282110e-01,  3.82985914e-01,  4.34736868e-01,  4.52303329e-01,\n",
       "        3.43145102e-01,  3.51537879e-01,  4.20571134e-01,  3.98326213e-01,\n",
       "        4.17531205e-01,  3.57297114e-01,  4.05297258e-01,  3.81181724e-01,\n",
       "        2.45855152e-01,  2.47534428e-01,  2.06510671e-01,  2.17002237e-01,\n",
       "        1.78161110e-01,  2.18245303e-01,  1.86070063e-01,  1.92136159e-01,\n",
       "        1.76976492e-01,  1.64466676e-01,  1.73213435e-01,  2.26442281e-01,\n",
       "        2.38210226e-01,  7.55829642e-02,  1.43875422e-01,  1.45744488e-01,\n",
       "        1.64741712e-01,  1.66916371e-01,  2.38397271e-01,  1.13563476e-01,\n",
       "        9.05528439e-02,  1.59460548e-01,  2.39226436e-01,  2.65068097e-01,\n",
       "        2.55332498e-01,  1.04138622e-01,  2.00757133e-01,  2.95765359e-01,\n",
       "        7.59951607e-01,  6.71247848e-01,  7.02758628e-01,  6.81881966e-01,\n",
       "        6.88558107e-01,  6.70897558e-01,  6.66477711e-01,  6.80921443e-01,\n",
       "        6.60506264e-01,  6.88879145e-01,  6.67009432e-01,  8.02768398e-01,\n",
       "        6.96464184e-01,  7.11781135e-01,  7.26705330e-01,  7.62817770e-01,\n",
       "        7.51259814e-01,  7.82181100e-01,  8.35570677e-01,  8.41675978e-01,\n",
       "        8.15617040e-01,  7.69315427e-01,  8.61282900e-01,  8.31934442e-01,\n",
       "        1.00000000e+00,  8.19557361e-01,  7.62303074e-01,  7.47721352e-01,\n",
       "        8.44185770e-01,  8.25563520e-01,  8.64532553e-01,  8.56523322e-01,\n",
       "        8.08869545e-01,  7.49786832e-01,  7.33273392e-01,  7.04579707e-01,\n",
       "        7.86517551e-01,  7.55934180e-01,  8.01503525e-01,  7.56802349e-01,\n",
       "        7.15447040e-01,  7.43437493e-01,  9.11899940e-01,  7.70302469e-01,\n",
       "        8.67295116e-01,  8.08155024e-01,  7.66859467e-01,  8.66268576e-01,\n",
       "        9.20232431e-01,  9.71732082e-01,  8.47425552e-01,  7.89838727e-01,\n",
       "        7.39713362e-01,  8.09630714e-01,  9.42016269e-01,  8.06781988e-01,\n",
       "        8.37326085e-01,  8.81389760e-01,  9.30356557e-01,  8.33203453e-01,\n",
       "        7.79567436e-01,  8.70968661e-01,  9.80044850e-01,  7.88615793e-01,\n",
       "        7.81985836e-01,  7.34178270e-01,  7.90685838e-01,  7.34592311e-01,\n",
       "        7.57703630e-01,  8.19464335e-01,  7.92400806e-01,  9.09999634e-01,\n",
       "        7.39192023e-01,  7.64019478e-01,  7.54069361e-01,  7.71829905e-01,\n",
       "        7.25177932e-01,  7.10126569e-01,  8.05753994e-01,  7.82672832e-01,\n",
       "        8.09503752e-01,  8.14855566e-01,  8.03968434e-01,  7.64597864e-01,\n",
       "        8.53962805e-01,  7.68251728e-01,  7.11714461e-01,  7.70828871e-01,\n",
       "        7.97041260e-01,  7.77986363e-01,  7.22612815e-01,  7.70390053e-01,\n",
       "        7.63909566e-01,  7.41425965e-01,  7.29531975e-01,  7.07468399e-01,\n",
       "        7.00488234e-01,  7.51016915e-01,  7.65960152e-01,  6.93299700e-01,\n",
       "        6.91443106e-01,  7.50412170e-01,  7.44526287e-01,  7.30824409e-01,\n",
       "        6.94607891e-01,  6.66900639e-01,  7.28548728e-01,  7.14535650e-01,\n",
       "        7.45695788e-01,  6.50699661e-01,  6.69195994e-01,  6.85763583e-01,\n",
       "        8.17568778e-01,  7.99248539e-01,  6.84009286e-01,  6.76257668e-01,\n",
       "        6.63312732e-01,  6.90950002e-01,  7.48547320e-01,  7.24347271e-01,\n",
       "        6.95889622e-01,  8.13789309e-01,  7.73590930e-01,  8.08869545e-01,\n",
       "        7.14587071e-01,  7.12484062e-01,  7.12904659e-01,  6.38603402e-01,\n",
       "        6.20842138e-01,  6.66348133e-01,  7.12182308e-01,  6.95118745e-01,\n",
       "        3.32129244e-01,  3.52559043e-01,  3.65480666e-01,  2.94927199e-01,\n",
       "        3.00310731e-01,  3.46652251e-01,  3.96709887e-01,  3.50028159e-01,\n",
       "        4.00399842e-01,  3.92433600e-01,  3.80348856e-01,  3.49347503e-01,\n",
       "        3.73688285e-01,  2.40099241e-01,  2.06118287e-01,  2.36925934e-01,\n",
       "        2.98671060e-01,  2.10953574e-01])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_predictions = sk_model.predict(predictors_sk)\n",
    "sk_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0780c8df60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(sk_predictions)\n",
    "sns.distplot(boston_features[\"CRIM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the formulas of R-squared and adjusted-R-squared below, and your Python/numpy knowledge, compute them and contrast them with the R-squared and adjusted-R-squared in your statsmodels output using stepwise selection. Which of the two models would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$SS_{residual} = \\sum (y - \\hat{y})^2 $\n",
    "\n",
    "$SS_{total} = \\sum (y - \\bar{y})^2 $\n",
    "\n",
    "$R^2 = 1- \\dfrac{SS_{residual}}{SS_{total}}$\n",
    "\n",
    "$R^2_{adj}= 1-(1-R^2)\\dfrac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform variable selection using forward selection, using this resource: https://planspace.org/20150423-forward_selection_with_statsmodels/. Note that this time features are added based on the adjusted-R-squared!\n",
    "- Tweak the code in the `stepwise_selection()`-function written above to just perform forward selection based on the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Great! You now performed your own feature selection methods!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
